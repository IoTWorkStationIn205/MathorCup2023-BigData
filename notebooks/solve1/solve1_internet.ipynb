{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import klib as kl\n",
    "import missingno as mns\n",
    "import os\n",
    "import warnings\n",
    "import tqdm\n",
    "import numba\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.sans-serif'] = ['Kaiti']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "PIC_PATH = \"../../models/image/image1/internet\"\n",
    "DATA_PATH = '../../data'\n",
    "RESULT_PATH = '../../data/summary/'\n",
    "MODEL_PATH = '../../models/model1'\n",
    "import pathlib2 as pl2\n",
    "import shutil\n",
    "\n",
    "\n",
    "def creat_dir():\n",
    "    pic_path = pl2.Path(PIC_PATH)\n",
    "    if os.path.exists(PIC_PATH):\n",
    "        shutil.rmtree(PIC_PATH)\n",
    "    pic_path.mkdir(parents=True, exist_ok=True)\n",
    "    if not os.path.exists(RESULT_PATH):\n",
    "        os.mkdir(RESULT_PATH)\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.mkdir(MODEL_PATH)\n",
    "\n",
    "\n",
    "creat_dir()\n",
    "figure_count = 0\n",
    "\n",
    "\n",
    "def create_figure(figure_name, dpi=800):\n",
    "    global figure_count\n",
    "    figure_count += 1\n",
    "    plt.savefig(PIC_PATH + f'/figure{figure_count}_{figure_name}.png', dpi=dpi)\n",
    "\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "def save_model(model, model_name: str) -> None:\n",
    "    dump(model, MODEL_PATH + model_name)\n",
    "\n",
    "\n",
    "def load_model(model_name: str):\n",
    "    return load(MODEL_PATH + model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "internet = pd.read_excel(DATA_PATH + '/附件2上网业务用户满意度数据.xlsx', index_col=0)\n",
    "test = pd.read_excel(DATA_PATH + '/附件4上网业务用户满意度预测数据.xlsx', index_col=0)\n",
    "\n",
    "internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test['场景备注数据'] = test['注明内容']\n",
    "test['现象备注数据'] = test['注明内容.1']\n",
    "test['APP大类备注'] = test[np.nan]\n",
    "test['APP小类视频备注'] = test['注明内容.2']\n",
    "test['APP小类游戏备注'] = test['注明内容.3']\n",
    "test['APP小类上网备注'] = test['注明内容.4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "col = [i for i in internet.columns if i not in test.columns][4:]\n",
    "inter_drop = internet[col]\n",
    "internet.drop(col, axis=1, inplace=True)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "col = [i for i in test.columns if i not in internet.columns]\n",
    "test_drop = test[col]\n",
    "test.drop(col, axis=1, inplace=True)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "columns = internet.columns[4:-12]\n",
    "columns = [column for column in columns if '备注' not in column]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "internet[columns] = internet[columns].applymap(lambda x: 0 if x == -1 else 1)\n",
    "internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "unique = internet[internet['其他，请注明'] != 0]\n",
    "unique['场景备注数据'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def replace_place(data: pd.DataFrame, bad_data:pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    对特别注明的信号不好的地区进行矫正\n",
    "    :param data: 原始数据\n",
    "    :param bad_data: 需要矫正的数据\n",
    "    :param col_name: 需要矫正的列\n",
    "    :return: 替换后的原始数据\n",
    "    \"\"\"\n",
    "\n",
    "    replace_value = ['地下', '电梯', '<NA>', '道路', '山区', '医院', '全部', np.nan]\n",
    "    data[col_name] = 0\n",
    "    bad_data[col_name] = 0\n",
    "\n",
    "    replace1 = bad_data.query('场景备注数据.str.contains(\"地下|地铁|地库|车库|地库\")')\n",
    "    replace1[col_name] += 1\n",
    "\n",
    "    replace2 = bad_data.query('场景备注数据.str.contains(\"电梯\")')\n",
    "    replace2[col_name] += 1\n",
    "\n",
    "    replace3 = bad_data.query('场景备注数据.str.contains(\"家|小区|公寓|住|屋\")')\n",
    "    # replace3[col_name] = '<NA>'\n",
    "    replace3['居民小区'] = 1\n",
    "\n",
    "    replace4 = bad_data.query('场景备注数据.str.contains(\"村|乡\")')\n",
    "    # replace4[col_name] = '<NA>'\n",
    "    replace4['农村'] = 1\n",
    "\n",
    "    replace5 = bad_data.query('场景备注数据.str.contains(\"路|环|途|车|街\")')\n",
    "    replace5[col_name] += 1\n",
    "\n",
    "    replace6 = bad_data.query('场景备注数据.str.contains(\"山\")')\n",
    "    replace6[col_name] += 1\n",
    "\n",
    "    replace7 = bad_data.query('场景备注数据.str.contains(\"医院\")')\n",
    "    replace7[col_name] += 1\n",
    "\n",
    "    replace8 = bad_data.query('场景备注数据.str.contains(\"超市|市场|集市\")')\n",
    "    replace8[col_name] += 1\n",
    "\n",
    "    data.update(replace1)\n",
    "    data.update(replace2)\n",
    "    data.update(replace3)\n",
    "    data.update(replace4)\n",
    "    data.update(replace5)\n",
    "    data.update(replace6)\n",
    "    data.update(replace7)\n",
    "    data.update(replace8)\n",
    "\n",
    "    # replace9 = bad_data.query('not 场景备注数据 in @replace_value')\n",
    "    # replace9[col_name] += 1\n",
    "    # data.update(replace9)\n",
    "    replace10 = bad_data.query('场景备注数据.str.contains(\"哪|都|所有|任何\")')\n",
    "    replace10[col_name] = 10\n",
    "    data.update(replace10)\n",
    "\n",
    "    data[col_name] += data.loc[:, '居民小区': '高铁'].astype(int).sum(axis=1)\n",
    "    data.drop(data.loc[:, '居民小区': '场景备注数据'].columns, axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def entire(data: pd.DataFrame=internet, col_name: str='全部都卡顿', target_col: str=None):\n",
    "    # print(data.columns)\n",
    "    data[target_col] = data[col_name].apply(lambda x: 10 if x else x)\n",
    "    data.drop(col_name, axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_feature(data: pd.DataFrame, bad_col: pd.DataFrame):\n",
    "    # data = df.copy()\n",
    "    data = replace_place(data, bad_col, '场景问题次数')\n",
    "    data['现象问题次数'] = data.loc[:, '网络信号差/没有信号': '手机上网速度慢'].astype(int).sum(axis=1)\n",
    "    data.drop(data.loc[:, '网络信号差/没有信号': '现象备注数据'].columns, axis=1, inplace=True)\n",
    "    data['大类问题次数'] = data.loc[:, '看视频卡顿': '手机支付较慢'].astype(int).sum(axis=1)\n",
    "    data.drop(data.loc[:, '看视频卡顿': 'APP大类备注'].columns, axis=1, inplace=True)\n",
    "    data['小类视频问题次数'] = data.loc[:, '爱奇艺': '咪咕视频'].astype(int).sum(axis=1)\n",
    "    data.drop(data.loc[:, '爱奇艺': 'APP小类视频备注'].columns, axis=1, inplace=True)\n",
    "    data = entire(data, target_col='小类视频问题次数', col_name='全部都卡顿')\n",
    "    data['小类游戏问题次数'] = data.loc[:, '和平精英': '阴阳师'].astype(int).sum(axis=1)\n",
    "    data.drop(data.loc[:, '和平精英': 'APP小类游戏备注'].columns, axis=1, inplace=True)\n",
    "    data = entire(data, '全部游戏都卡顿', target_col='小类游戏问题次数')\n",
    "    data['全部应用问题次数'] = data.loc[:, '微信': '拼多多'].astype(int).sum(axis=1)\n",
    "    data.drop(data.loc[:, '微信': 'APP小类上网备注'], axis=1, inplace=True)\n",
    "    data = entire(data, '全部网页或APP都慢', target_col='全部应用问题次数')\n",
    "    return data\n",
    "\n",
    "col = internet.columns[4:]\n",
    "internet = get_feature(internet, unique)\n",
    "internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "kl.missingval_plot(internet)\n",
    "create_figure('missing_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def boolean_replace(x):\n",
    "    if x not in ['是', '否']:\n",
    "        return x\n",
    "    return 1 if x == '是' else 0\n",
    "\n",
    "def missing_clean(data: pd.DataFrame):\n",
    "    data[['上网质差次数', '脱网次数', '微信质差次数']] = data[['上网质差次数', '脱网次数', '微信质差次数']].fillna(0)\n",
    "    data.dropna(axis=0, inplace=True)\n",
    "    data = data.applymap(boolean_replace)\n",
    "    return data\n",
    "\n",
    "internet = missing_clean(internet)\n",
    "internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "shell = internet['终端品牌'].unique()\n",
    "shell_type = internet['终端品牌类型'].unique()\n",
    "\n",
    "def data_clean(data: pd.DataFrame):\n",
    "    data['终端品牌'] = data['终端品牌'].astype(str)\n",
    "    replace = data.query('终端品牌.str.contains(\"移动|联通|电信\")')\n",
    "    replace['终端品牌'] = '其他'\n",
    "    data.update(replace)\n",
    "    data['终端品牌'] = data['终端品牌'].replace([0, '0'], '其他')\n",
    "    data['终端品牌'] = data['终端品牌'].apply(lambda x: '其他' if x not in shell else x)\n",
    "    data['终端品牌类型'] = data['终端品牌类型'].apply(lambda x: '其他' if x not in shell_type else x)\n",
    "    _ = data['终端品牌类型'].apply(lambda x: ' '.join(x.split(' ')[:2]) if isinstance(x, str) else '其他').apply(\n",
    "        lambda x: x.split('-')[0]\n",
    "    ).apply(\n",
    "        lambda x: x.split('_')[0]\n",
    "    )\n",
    "    data['终端品牌类型'] = _.apply(check)\n",
    "\n",
    "    return data['终端品牌类型'].unique()\n",
    "\n",
    "def check(string: str):\n",
    "    import re\n",
    "    if ' ' in string:\n",
    "        return string.split(' ')[0]\n",
    "    if re.match(r'^\\d', string):\n",
    "        return 'Num'\n",
    "    re_str = r'A\\d{4}'\n",
    "    if re.match(re_str, string, re.I):\n",
    "        return 'A_Num'\n",
    "    if re.match(r'\\D+', string, re.I):\n",
    "        return 'word'\n",
    "    if re.match(r'^HM', string, re.I):\n",
    "        return 'HM'\n",
    "    if re.match(r'^RMX\\d+', string):\n",
    "        return 'type_rmx'\n",
    "    if re.match(r'^M.+[A-Z]$', string):\n",
    "        return 'type_m'\n",
    "    if re.match(r'^P.+0$', string):\n",
    "        return 'type_p'\n",
    "    if re.match(r'V\\d+[A-Za-z]', string):\n",
    "        return 'type_v'\n",
    "    if re.match(r'^[A-Za-z].+\\d+', string):\n",
    "        return 'num_object'\n",
    "    return '其他'\n",
    "\n",
    "data_clean(internet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_encoder(data: pd.DataFrame):\n",
    "    ll1 = LabelEncoder().fit(data['终端品牌'].astype(str))\n",
    "    data['终端品牌'] = ll1.transform(data['终端品牌'].astype(str))\n",
    "    save_model(ll1, '/LabelEncoder_3.model')\n",
    "\n",
    "    ll2 = LabelEncoder().fit(data['终端品牌类型'].astype(str))\n",
    "    data['终端品牌类型'] = ll2.transform(data['终端品牌类型'].astype(str))\n",
    "    save_model(ll2, '/LabelEncoder_4.model')\n",
    "\n",
    "    return star_map(data)\n",
    "\n",
    "def star_map(data: pd.DataFrame):\n",
    "    dct = {\n",
    "            '未评级': -1,\n",
    "            '准星': 0,\n",
    "            '一星': 1,\n",
    "            '二星': 2,\n",
    "            '三星': 3,\n",
    "            '银卡': 4,\n",
    "            '金卡': 5,\n",
    "            '白金卡': 6,\n",
    "            '钻石卡': 7\n",
    "        }\n",
    "    data['客户星级标识'] = data['客户星级标识'].apply(lambda x: dct.get(x))\n",
    "    return pd.get_dummies(data, columns=['性别'])\n",
    "\n",
    "internet = label_encoder(internet)\n",
    "internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train = internet.iloc[:, 4:]\n",
    "target = internet.iloc[:, :4].astype(np.int64)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import  classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "def split_data(train_data, predict):\n",
    "\n",
    "    return train_test_split(train_data, predict, test_size=.3, random_state=42)\n",
    "\n",
    "def train_model(train_data, predict):\n",
    "    X_train, X_test, y_train, y_test = split_data(train_data, predict)\n",
    "    models = [DecisionTreeClassifier(), KNeighborsClassifier(), RandomForestClassifier(),\n",
    "              GradientBoostingClassifier(), XGBClassifier(), LGBMClassifier()]\n",
    "    scores = pd.DataFrame()\n",
    "    y_test = y_test.astype(np.int64)\n",
    "\n",
    "    for model in models:\n",
    "        print(model.__class__.__name__)\n",
    "        reports = ''\n",
    "        acc = []\n",
    "        f1 = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        for col in y_test.columns:\n",
    "            print(col)\n",
    "            try:\n",
    "                model.fit(X_train, y_train[col])\n",
    "                pre = model.predict(X_test)\n",
    "            except ValueError:\n",
    "                ll = LabelEncoder().fit(y_train[col])\n",
    "                model.fit(X_train, ll.transform(y_train[col]))\n",
    "                pre = ll.inverse_transform(model.predict(X_test))\n",
    "            acc.append(model.score(X_test, y_test[col]))\n",
    "            f1.append(f1_score(y_test[col], pre, average='micro'))\n",
    "            precision.append(precision_score(y_test[col], pre, average='weighted'))\n",
    "            recall.append(recall_score(y_test[col], pre, average='weighted'))\n",
    "            report = classification_report(y_test[col], pre)\n",
    "            reports += report\n",
    "        with open(RESULT_PATH + model.__class__.__name__ + '_internet.txt', 'w') as f:\n",
    "            f.write(reports)\n",
    "\n",
    "\n",
    "        scores[f'{model.__class__.__name__}'] = [np.mean(np.array(acc)), np.mean(f1), np.mean(precision), np.mean(recall)]\n",
    "\n",
    "    return scores\n",
    "\n",
    "train_model(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i in target.columns:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    counts = target[i].value_counts()\n",
    "    plt.pie(counts, labels=counts.index, autopct=\"%1.1f%%\")\n",
    "    create_figure(f'{i}_describe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "internet.iloc[:, 0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "internet.iloc[:, :4] = internet.iloc[:, :4].astype(np.int64)\n",
    "internet.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "regress_feature = ['套外流量（MB）', '套外流量费（元）', '当月MOU']\n",
    "classic_feature = [col for col in internet.columns if col not in regress_feature]\n",
    "internet[regress_feature] = internet[regress_feature].astype(np.float64)\n",
    "internet[classic_feature] = internet[classic_feature].astype(np.int64)\n",
    "\n",
    "internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from imblearn.over_sampling import SVMSMOTE,SMOTEN\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def get_data(data: pd.DataFrame):\n",
    "    temp = pd.DataFrame()\n",
    "    for i in range(1, 11):\n",
    "        query = data.query('手机上网整体满意度 == @i')\n",
    "        if 60 <= query.__len__() <120:\n",
    "            sample = 60\n",
    "        elif 120 <= query.__len__() < 180:\n",
    "            sample = 100\n",
    "        else:\n",
    "            sample = 180\n",
    "        temp = pd.concat([temp, data.sample(sample)], axis=0)\n",
    "    return temp\n",
    "\n",
    "def oversampling(data: pd.DataFrame):\n",
    "    value_counts = data.iloc[:, 0].value_counts()\n",
    "    _index = value_counts[value_counts<value_counts.max()].index.tolist()\n",
    "    sm = SVMSMOTE()\n",
    "    # print(data)\n",
    "    X, y = sm.fit_resample(data.iloc[:, 4:], data[['手机上网整体满意度']].values.reshape((-1, 1)))\n",
    "    frame = data.iloc[:, :4]\n",
    "    y = pd.DataFrame(y[frame.shape[0]:], columns=[data.columns[0]])\n",
    "    frame = pd.concat([frame, y], axis=0)\n",
    "    frame = pd.DataFrame(KNNImputer(n_neighbors=4).fit_transform(frame).astype(np.int64), columns=frame.columns)\n",
    "    return pd.concat([frame, X], axis=1)\n",
    "\n",
    "def split_train_test(init_data):\n",
    "    _train = init_data.iloc[:, 4:]\n",
    "    _target = init_data.iloc[:, :4]\n",
    "    return _target, _train\n",
    "\n",
    "def false_target(data: pd.DataFrame, _model=RandomForestClassifier()):\n",
    "    init_data = pd.DataFrame()\n",
    "    _best_score = 0\n",
    "    for i in range(40):\n",
    "        if i == 0:\n",
    "            init_data = oversampling(get_data(data))\n",
    "        init_data.drop_duplicates(inplace=True)\n",
    "        _target, _train = split_train_test(init_data)\n",
    "        _model.fit(_train, _target)\n",
    "\n",
    "        new_data =get_data(data)\n",
    "        _test_target, _test_train = split_train_test(new_data)\n",
    "\n",
    "        _pre = pd.Series(_model.predict(_test_train)[:, 0])\n",
    "        _score = accuracy_score(_pre, _test_target.iloc[:, 0])\n",
    "        _f1 = f1_score(_pre, _test_target.iloc[:, 0], average='weighted')\n",
    "        _best_score = max(_best_score, _f1)\n",
    "        print(_score, _f1)\n",
    "\n",
    "        _proba_max = pd.DataFrame(_model.predict_proba(_test_train)[0], index=_test_train.index).max(axis=1)\n",
    "        _proba_max = _proba_max[_proba_max > .5]\n",
    "\n",
    "\n",
    "        _pre.index = _test_target.index\n",
    "        _pre = _pre[_pre==_test_target.iloc[:, 0]]\n",
    "        _index = [i for i in _pre.index if i in _proba_max.index]\n",
    "        init_data = pd.concat([init_data, new_data.loc[_index]], axis=0)\n",
    "\n",
    "        if _f1 > .5 and _best_score - _f1 < .01:\n",
    "            save_model(_model, '/best_model_internet.model')\n",
    "    return _model, _best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "rf, best_score = false_target(internet, RandomForestClassifier())\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f1_score(target.手机上网整体满意度, rf.predict(train)[:, 0], average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bm = load_model('/best_model_internet.model')\n",
    "accuracy_score(target.手机上网整体满意度, bm.predict(train)[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "result = pd.read_excel(DATA_PATH + '/result.xlsx', sheet_name='上网', index_col=0)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def label_transform(data: pd.DataFrame):\n",
    "    ll1 = load_model('/LabelEncoder_3.model')\n",
    "    ll2 = load_model('/LabelEncoder_4.model')\n",
    "    data['终端品牌'] = ll1.transform(data['终端品牌'].astype(str))\n",
    "    data['终端品牌类型'] = ll2.transform(data['终端品牌类型'].astype(str))\n",
    "    return star_map(data)\n",
    "\n",
    "def pipeline(data: pd.DataFrame):\n",
    "    data[columns] = data[columns].applymap(lambda x: 0 if x == -1 else 1)\n",
    "    bad_col = data[data['其他，请注明'] != 0]\n",
    "    # print(bad_col)\n",
    "    data = get_feature(data, bad_col)\n",
    "    data = missing_clean(data)\n",
    "    data_clean(data)\n",
    "    data = label_transform(data)\n",
    "    data[regress_feature] = data[regress_feature].astype(np.float64)\n",
    "    data[[i for i in classic_feature if i in data.columns]] = data[[i for i in classic_feature if i in data.columns]].astype(np.int64)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test = test[col]\n",
    "test_ = test.copy()\n",
    "\n",
    "test_ = pipeline(test_)\n",
    "test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test_ = test_[internet.columns[4:]]\n",
    "test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "res = bm.predict(test_)\n",
    "result = pd.DataFrame(res, index=result.index, columns=result.columns)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "result.to_excel(DATA_PATH + '/result.xlsx', index=True, sheet_name='上网')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "internet.to_csv(RESULT_PATH + '/internet.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
