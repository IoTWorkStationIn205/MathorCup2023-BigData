{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import klib as kl\n",
    "import missingno as mns\n",
    "import os\n",
    "import warnings\n",
    "import tqdm\n",
    "import numba\n",
    "\n",
    "\n",
    "os.environ['KERAS_BACKEND']='tensorflow'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.sans-serif'] = ['Kaiti']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "PIC_PATH = \"../../models/image/image1\"\n",
    "DATA_PATH = '../../data'\n",
    "RESULT_PATH = '../../data/summary/'\n",
    "MODEL_PATH = '../../models/model1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pathlib2 as pl2\n",
    "import shutil\n",
    "\n",
    "def creat_dir():\n",
    "    pic_path = pl2.Path(PIC_PATH)\n",
    "    if os.path.exists(PIC_PATH):\n",
    "        shutil.rmtree(PIC_PATH)\n",
    "    pic_path.mkdir(parents=True, exist_ok=True)\n",
    "    if not os.path.exists(RESULT_PATH):\n",
    "        os.mkdir(RESULT_PATH)\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.mkdir(MODEL_PATH)\n",
    "\n",
    "creat_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "figure_count = 0\n",
    "\n",
    "def create_figure(figure_name, dpi=800):\n",
    "    global figure_count\n",
    "    figure_count += 1\n",
    "    plt.savefig(PIC_PATH + f'/figure{figure_count}_{figure_name}.png', dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "def save_model(model, model_name: str) -> None:\n",
    "    dump(model, MODEL_PATH + model_name)\n",
    "\n",
    "def load_model(model_name: str):\n",
    "    return load(MODEL_PATH + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def read_excel(base_path: str=DATA_PATH, file_name: str=None, index_col: int=0):\n",
    "    return pd.read_excel(base_path + file_name, index_col=index_col)\n",
    "\n",
    "def save_excel(data: pd.DataFrame, base_path=RESULT_PATH, file_name: str=None, index=True):\n",
    "    data.to_csv(base_path+file_name, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sound = read_excel(file_name='/附件1语音业务用户满意度数据.xlsx')\n",
    "test = read_excel(file_name='/附件3语音业务用户满意度预测数据.xlsx')\n",
    "\n",
    "sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "col = [i for i in sound.columns if i not in test.columns][4:]\n",
    "[col.remove(i)  for i in ['家宽投诉', '资费投诉']]\n",
    "sound.drop(col, axis= 1, inplace=True)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "col = [i for i in test.columns if i not in sound.columns][1:]\n",
    "test.drop(col, axis=1, inplace=True)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "kl.missingval_plot(sound)\n",
    "create_figure('sound_missing_plot', dpi=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mns.heatmap(sound)\n",
    "create_figure('sound_missing_heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sound_columns = sound.columns\n",
    "sound_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sound_score = sound_columns[: 4]\n",
    "sound_dummies = sound_columns[5: 22].drop('用户描述').drop('用户描述.1')\n",
    "sound_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "place = sound_dummies[:7]\n",
    "question = sound_dummies[8:-1]\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sound[['家宽投诉', '资费投诉']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def complain(data: pd.DataFrame):\n",
    "    data['是否投诉'] = data[['家宽投诉', '资费投诉']].sum(axis=1).apply(lambda x: min(1, x))\n",
    "    data.drop(['家宽投诉', '资费投诉'], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "complain(sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def encoder(data):\n",
    "    return data if data == -1 else 1\n",
    "\n",
    "sound[sound_dummies] = sound[sound_dummies].fillna(-1).applymap(encoder)\n",
    "sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import toad\n",
    "\n",
    "missing_rate: pd.DataFrame = toad.detect(sound)[['missing']].applymap(lambda x: x[:-1]).astype(np.float64)\n",
    "missing_rate = missing_rate.query('missing > 0')\n",
    "missing_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def drop_treat(data: pd.DataFrame):\n",
    "    sound_bad_data = data.query(\n",
    "        '`用户描述.1` == \"没有\"'\n",
    "    )\n",
    "    sound_bad_data = sound_bad_data[sound_bad_data['其他，请注明.1'] == 1]\n",
    "    data.drop(sound_bad_data.index, inplace=True)\n",
    "    return sound_bad_data\n",
    "\n",
    "sound_bad_data = drop_treat(sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sound['其他，请注明'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sound_bad_data = sound[sound['其他，请注明'] == 1]\n",
    "sound_bad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%s\n"
    }
   },
   "outputs": [],
   "source": [
    "def replace_place(data: pd.DataFrame, bad_data:pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    对特别注明的信号不好的地区进行矫正\n",
    "    :param data: 原始数据\n",
    "    :param bad_data: 需要矫正的数据\n",
    "    :param col_name: 需要矫正的列\n",
    "    :return: 替换后的原始数据\n",
    "    \"\"\"\n",
    "\n",
    "    replace_value = ['地下', '电梯', '<NA>', '道路', '山区', '医院', '信号', np.nan, '无']\n",
    "\n",
    "    replace1 = bad_data.query('用户描述.str.contains(\"地下|地铁|地库|车库\")')\n",
    "    replace1[col_name] = '地下'\n",
    "\n",
    "    replace2 = bad_data.query('用户描述.str.contains(\"电梯\")')\n",
    "    replace2[col_name] = '电梯'\n",
    "\n",
    "    replace3 = bad_data.query('用户描述.str.contains(\"家|小区|公寓|住|屋\")')\n",
    "    replace3[col_name] = '<NA>'\n",
    "    replace3['居民小区'] = 1\n",
    "\n",
    "    replace4 = bad_data.query('用户描述.str.contains(\"村|乡\")')\n",
    "    replace4[col_name] = '<NA>'\n",
    "    replace4['农村'] = 1\n",
    "\n",
    "    replace5 = bad_data.query('用户描述.str.contains(\"路|环|途|车|街\")')\n",
    "    replace5[col_name] = '道路'\n",
    "\n",
    "    replace6 = bad_data.query('用户描述.str.contains(\"山\")')\n",
    "    replace6[col_name] = '山区'\n",
    "\n",
    "    replace7 = bad_data.query('用户描述.str.contains(\"医院\")')\n",
    "    replace7[col_name] = '医院'\n",
    "\n",
    "    replace8 = bad_data.query('用户描述.str.contains(\"信号|网络|中断|接|打\")')\n",
    "    replace8[col_name] = '信号'\n",
    "\n",
    "    data.update(replace1)\n",
    "    data.update(replace2)\n",
    "    data.update(replace3)\n",
    "    data.update(replace4)\n",
    "    data.update(replace5)\n",
    "    data.update(replace6)\n",
    "    data.update(replace7)\n",
    "    data.update(replace8)\n",
    "\n",
    "    replace9 = bad_data.query('not 用户描述 in @replace_value')\n",
    "    replace9[col_name] = '其他'\n",
    "    data.update(replace9)\n",
    "    return data\n",
    "\n",
    "sound_new = replace_place(sound, sound_bad_data, '用户描述')\n",
    "sound_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "独热编码及后续相关处理\n",
    "\"\"\"\n",
    "\n",
    "def get_dummies(data: pd.DataFrame, process_col='用户描述'):\n",
    "    data[process_col].fillna('<NA>', inplace=True)\n",
    "    data[process_col] = data[process_col].astype(str)\n",
    "    data[process_col] = data[process_col].str.replace('无', '<NA>')\n",
    "    return pd.get_dummies(data, columns=[process_col])\n",
    "\n",
    "\n",
    "def dummies_process(data: pd.DataFrame, process_col='用户描述', about_col='其他，请注明', save_name=None) -> pd.DataFrame:\n",
    "    department = get_dummies(data, process_col)\n",
    "    department.drop([about_col], axis=1, inplace=True)\n",
    "    dummies_columns = [i for i in department.columns if '_' in i]\n",
    "    drop_columns = [i for i in dummies_columns if 'NA' in i]\n",
    "    [dummies_columns.remove(col) for col in drop_columns]\n",
    "    department = department.drop(drop_columns, axis=1)\n",
    "    department[dummies_columns] = department[dummies_columns].applymap(lambda x: x if x == 1 else -1)\n",
    "    columns = pd.Series(department.columns)\n",
    "    process_columns = columns.apply(lambda x: x.split('_')[1] if len(x.split('_'))>1 else x)\n",
    "\n",
    "    if process_columns.duplicated().any():\n",
    "        index = process_columns[process_columns.duplicated()].index\n",
    "        process_columns[index] = process_columns[index] + '.1'\n",
    "    department.columns = process_columns\n",
    "    if save_name:\n",
    "        save_excel(department, RESULT_PATH, save_name, True)\n",
    "    return department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dummies = dummies_process(sound_new)\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sound_bad_data = sound[sound['其他，请注明.1'] == 1]\n",
    "\n",
    "def replace_question(data: pd.DataFrame, bad_data: pd.DataFrame, col: str='用户描述.1'):\n",
    "\n",
    "    replace_value = question.copy().tolist()\n",
    "    replace_value.append('<NA>')\n",
    "\n",
    "    replace1 = bad_data.query('`用户描述.1`.str.contains(\"信号|2G|3G|4G|5G|基站\")')\n",
    "    replace1[col] = '<NA>'\n",
    "    replace1[question[0]] = 1\n",
    "    replace2 = bad_data.query('`用户描述.1`.str.contains(\"通话|拨打|接通\")')\n",
    "    replace2[col] = '<NA>'\n",
    "    replace2[question[1]] = 1\n",
    "    replace3 = bad_data.query('`用户描述.1`.str.contains(\"断\")')\n",
    "    replace3[col] = '<NA>'\n",
    "    replace3[question[2]] = 1\n",
    "    replace4 = bad_data.query('`用户描述.1`.str.contains(\"杂|清|断续\")')\n",
    "    replace4[col] = '<NA>'\n",
    "    replace4[question[3]] = 1\n",
    "\n",
    "    data.update(replace1)\n",
    "    data.update(replace2)\n",
    "    data.update(replace3)\n",
    "    data.update(replace4)\n",
    "\n",
    "    replace9 = bad_data.query('not `用户描述.1` in @replace_value')\n",
    "    replace9[col] = '其他'\n",
    "    data.update(replace9)\n",
    "    return data\n",
    "\n",
    "dummies_new = replace_question(dummies, sound_bad_data)\n",
    "dummies_new = dummies_process(dummies_new, '用户描述.1', '其他，请注明.1', 'one_hot.csv')\n",
    "dummies_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def boolean_replace(x):\n",
    "    if x not in ['是', '否']:\n",
    "        return x\n",
    "    return 1 if x == '是' else -1\n",
    "\n",
    "def missing_clean(data: pd.DataFrame):\n",
    "    # data[['重定向次数', '重定向驻留时长']] = data[['重定向次数', '重定向驻留时长']].fillna(0,)\n",
    "    data['4\\\\5G用户'] = data['4\\\\5G用户'].apply(lambda x: x[0])\n",
    "    data['是否关怀用户'] = data['是否关怀用户'].fillna('否',)\n",
    "    data = data.applymap(boolean_replace)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def sample_clean(data: pd.DataFrame):\n",
    "    data = missing_clean(data)\n",
    "    # 7 samples\n",
    "    data.dropna(axis=0, inplace=True)\n",
    "    # data = pd.get_dummies(data, columns=['语音方式'])\n",
    "\n",
    "    return data\n",
    "\n",
    "dummies_new = sample_clean(dummies_new)\n",
    "dummies_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "shell = dummies_new['终端品牌'].unique()\n",
    "shell_type = dummies_new['终端品牌类型'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def data_clean(data: pd.DataFrame):\n",
    "    data['终端品牌'] = data['终端品牌'].apply(lambda x: '其他' if x not in shell else x)\n",
    "    data['终端品牌类型'] = data['终端品牌类型'].apply(lambda x: '其他' if x not in shell_type else x)\n",
    "    _ = data['终端品牌类型'].apply(lambda x: ' '.join(x.split(' ')[:2]) if isinstance(x, str) else '其他').apply(\n",
    "        lambda x: x.split('-')[0]\n",
    "    ).apply(\n",
    "        lambda x: x.split('_')[0]\n",
    "    )\n",
    "    data['终端品牌类型'] = _.apply(check)\n",
    "\n",
    "    return data['终端品牌类型'].unique()\n",
    "\n",
    "def check(string: str):\n",
    "    import re\n",
    "    if ' ' in string:\n",
    "        return string.split(' ')[0]\n",
    "    if re.match(r'^\\d', string):\n",
    "        return 'Num'\n",
    "    re_str = r'A\\d{4}'\n",
    "    if re.match(re_str, string, re.I):\n",
    "        return 'A_Num'\n",
    "    if re.match(r'\\D+', string, re.I):\n",
    "        return 'word'\n",
    "    if re.match(r'^HM', string, re.I):\n",
    "        return 'HM'\n",
    "    if re.match(r'^RMX\\d+', string):\n",
    "        return 'type_rmx'\n",
    "    if re.match(r'^M.+[A-Z]$', string):\n",
    "        return 'type_m'\n",
    "    if re.match(r'^P.+0$', string):\n",
    "        return 'type_p'\n",
    "    if re.match(r'V\\d+[A-Za-z]', string):\n",
    "        return 'type_v'\n",
    "    if re.match(r'^[A-Za-z].+\\d+', string):\n",
    "        return 'num_object'\n",
    "    return '其他'\n",
    "\n",
    "data_clean(dummies_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "ll1 = LabelEncoder().fit(dummies_new['终端品牌'].astype(str))\n",
    "dummies_new['终端品牌'] = ll1.transform(dummies_new['终端品牌'].astype(str))\n",
    "save_model(ll1, '/LabelEncoder_1.model')\n",
    "\n",
    "ll2 = LabelEncoder().fit(dummies_new['终端品牌类型'].astype(str))\n",
    "dummies_new['终端品牌类型'] = ll2.transform(dummies_new['终端品牌类型'].astype(str))\n",
    "save_model(ll2, '/LabelEncoder_2.model')\n",
    "\n",
    "def star_map(data: pd.DataFrame):\n",
    "    dct = {\n",
    "            '未评级': -1,\n",
    "            '准星': 0,\n",
    "            '一星': 1,\n",
    "            '二星': 2,\n",
    "            '三星': 3,\n",
    "            '银卡': 4,\n",
    "            '金卡': 5,\n",
    "            '白金卡': 6,\n",
    "            '钻石卡': 7\n",
    "        }\n",
    "    data['客户星级标识'] = data['客户星级标识'].apply(lambda x: dct.get(x))\n",
    "    return data\n",
    "\n",
    "dummies = star_map(dummies_new)\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "float_feature = ['套外流量（MB）', '套外流量费（元）', '外省语音占比', '语音通话-时长（分钟）', '省际漫游-时长（分钟）',\n",
    "                 '当月ARPU', '当月MOU', '前3月ARPU', '前3月MOU', '外省流量占比', 'GPRS总流量（KB）', 'GPRS-国内漫游-流量（KB）',]\n",
    "class_feature = dummies.columns.drop(float_feature)\n",
    "\n",
    "dummies_n = dummies.copy()\n",
    "dummies_n[float_feature] = dummies[float_feature].astype(np.float64)\n",
    "dummies_n[class_feature] = dummies[class_feature].astype(np.int64)\n",
    "\n",
    "dummies_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "place_ = place.tolist()\n",
    "place_.extend(['其他', '医院', '地下', '山区', '电梯', '道路'])\n",
    "question_ = question.tolist()\n",
    "question_.append('其他.1')\n",
    "question_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_count(data:pd.DataFrame, drop: list, new_col: str=None):\n",
    "    series = (data[drop]==1).astype(int).sum(axis=1)\n",
    "    data.drop(drop, axis=1, inplace=True)\n",
    "    if new_col is None:\n",
    "        return series\n",
    "    data[new_col] = series\n",
    "    return data\n",
    "\n",
    "\n",
    "dummies_n['出现问题地点数'] = get_count(dummies_n, place_)\n",
    "dummies_n['出现问题数'] = get_count(dummies_n, question_)\n",
    "dummies_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "target = dummies_n.iloc[:, :4]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train = dummies_n.iloc[:, 4:]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import  classification_report, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def split_data(train_data, predict):\n",
    "\n",
    "    return train_test_split(train_data, predict, test_size=.3, random_state=42)\n",
    "\n",
    "def train_model(train_data, predict):\n",
    "    X_train, X_test, y_train, y_test = split_data(train_data, predict)\n",
    "    models = [DecisionTreeClassifier(), KNeighborsClassifier(), RandomForestClassifier(),\n",
    "              GradientBoostingClassifier(), XGBClassifier(), LGBMClassifier()]\n",
    "    scores = pd.DataFrame()\n",
    "    y_test = y_test.astype(np.int64)\n",
    "\n",
    "    for model in models:\n",
    "        print(model.__class__.__name__)\n",
    "        reports = ''\n",
    "        acc = []\n",
    "        f1 = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        for col in y_test.columns:\n",
    "            print(col)\n",
    "            try:\n",
    "                model.fit(X_train, y_train[col])\n",
    "                pre = model.predict(X_test)\n",
    "            except ValueError:\n",
    "                ll = LabelEncoder().fit(y_train[col])\n",
    "                model.fit(X_train, ll.transform(y_train[col]))\n",
    "                pre = ll.inverse_transform(model.predict(X_test))\n",
    "            acc.append(model.score(X_test, y_test[col]))\n",
    "            f1.append(f1_score(y_test[col], pre, average='micro'))\n",
    "            precision.append(precision_score(y_test[col], pre, average='weighted'))\n",
    "            recall.append(recall_score(y_test[col], pre, average='weighted'))\n",
    "            report = classification_report(y_test[col], pre)\n",
    "            reports += report\n",
    "        with open(RESULT_PATH + model.__class__.__name__ + '.txt', 'w') as f:\n",
    "            f.write(reports)\n",
    "\n",
    "\n",
    "        scores[f'{model.__class__.__name__}'] = [np.mean(np.array(acc)), np.mean(f1), np.mean(precision), np.mean(recall)]\n",
    "        # score[f'{model.__class__.__name__}'] = np.mean(f1)\n",
    "        # score[f'{model.__class__.__name__}'] = np.mean(precision)\n",
    "        # score[f'{model.__class__.__name__}'] = np.mean(recall)\n",
    "\n",
    "    return scores\n",
    "\n",
    "score = train_model(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i in target.columns:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    counts = target[i].value_counts()\n",
    "    plt.pie(counts, labels=counts.index, autopct=\"%1.1f%%\")\n",
    "    create_figure(f'{i}_describe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from dataprep.eda.create_report import create_report\n",
    "\n",
    "create_report(dummies_n).show_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from autoviz.AutoViz_Class import AutoViz_Class\n",
    "\n",
    "av = AutoViz_Class()\n",
    "av.AutoViz(filename=None, depVar=\"语音通话整体满意度\", dfte=dummies_n, verbose=0, chart_format='png', save_plot_dir=PIC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "corr = dummies_n.corr(method='kendall')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.figure(figsize=(18, 18))\n",
    "mask = np.zeros_like(corr[corr.abs()>=.7],dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plt.rcParams['font.sans-serif'] = 'Kaiti'\n",
    "sns.heatmap(corr[corr>=.7],annot=True,mask=mask,cbar=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "kl.corr_plot(dummies_n, target='语音通话整体满意度', method='kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def get_data(data: pd.DataFrame):\n",
    "    temp = pd.DataFrame()\n",
    "    for i in range(1, 11):\n",
    "        query = data.query('语音通话整体满意度 == @i')\n",
    "        if query.__len__() < 60:\n",
    "            sample = 30\n",
    "        elif 60 <= query.__len__() <120:\n",
    "            sample = 60\n",
    "        else:\n",
    "            sample = 100\n",
    "        temp = pd.concat([temp, data.sample(sample)], axis=0)\n",
    "    return temp\n",
    "\n",
    "def oversampling(data: pd.DataFrame):\n",
    "    value_counts = data.iloc[:, 0].value_counts()\n",
    "    _index = value_counts[value_counts<value_counts.max()].index.tolist()\n",
    "    sm = SVMSMOTE()\n",
    "    # print(data.iloc[:, 4:].shape, data[['语音通话整体满意度']].iloc[:, 0].shape)\n",
    "    X, y = sm.fit_resample(data.iloc[:, 4:], data[['语音通话整体满意度']].values.reshape((-1, 1)))\n",
    "    frame = data.iloc[:, :4]\n",
    "    y = pd.DataFrame(y[frame.shape[0]:], columns=[data.columns[0]])\n",
    "    frame = pd.concat([frame, y], axis=0)\n",
    "    frame = pd.DataFrame(KNNImputer(n_neighbors=4).fit_transform(frame).astype(np.int64), columns=frame.columns)\n",
    "    return pd.concat([frame, X], axis=1)\n",
    "\n",
    "def split_train_test(init_data):\n",
    "    _train = init_data.iloc[:, 4:]\n",
    "    _target = init_data.iloc[:, :4]\n",
    "    return _target, _train\n",
    "\n",
    "def false_target(data: pd.DataFrame, _model=RandomForestClassifier()):\n",
    "    init_data = pd.DataFrame()\n",
    "    _best_score = 0\n",
    "    for i in range(40):\n",
    "        if i == 0:\n",
    "            init_data = oversampling(get_data(data))\n",
    "        init_data.drop_duplicates(inplace=True)\n",
    "        _target, _train = split_train_test(init_data)\n",
    "        _model.fit(_train, _target)\n",
    "\n",
    "        new_data =get_data(data)\n",
    "        _test_target, _test_train = split_train_test(new_data)\n",
    "\n",
    "        _pre = pd.Series(_model.predict(_test_train)[:, 0])\n",
    "        _score = accuracy_score(_pre, _test_target.iloc[:, 0])\n",
    "        _f1 = f1_score(_pre, _test_target.iloc[:, 0], average='weighted')\n",
    "        _best_score = max(_best_score, _f1)\n",
    "        print(_score, _f1)\n",
    "\n",
    "        _proba_max = pd.DataFrame(_model.predict_proba(_test_train)[0], index=_test_train.index).max(axis=1)\n",
    "        _proba_max = _proba_max[_proba_max > .5]\n",
    "\n",
    "\n",
    "        _pre.index = _test_target.index\n",
    "        _pre = _pre[_pre==_test_target.iloc[:, 0]]\n",
    "        _index = [i for i in _pre.index if i in _proba_max.index]\n",
    "        init_data = pd.concat([init_data, new_data.loc[_index]], axis=0)\n",
    "\n",
    "        if _f1 > .6 and _best_score - _f1 < .001:\n",
    "            save_model(_model, '/best_model.model')\n",
    "    return _model, _best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "rf, best_score = false_target(dummies_n, RandomForestClassifier())\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "best_model: RandomForestClassifier = load_model('/best_model.model')\n",
    "accuracy_score(best_model.predict(train)[:, 0], target.语音通话整体满意度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = confusion_matrix(target.语音通话整体满意度, best_model.predict(train)[:, 0])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def transform(_dummies):\n",
    "    model_1: LabelEncoder = load_model('/LabelEncoder_1.model')\n",
    "    model_2: LabelEncoder = load_model('/LabelEncoder_2.model')\n",
    "    _dummies['终端品牌'] = _dummies['终端品牌'].apply(lambda x: x if x in model_1.classes_ else '其他')\n",
    "    _dummies['终端品牌'] = model_1.transform(_dummies['终端品牌'].astype(str))\n",
    "    _dummies['终端品牌'] = _dummies['终端品牌'].apply(lambda x: x if x in model_1.classes_ else 0)\n",
    "    _dummies['终端品牌类型'] = model_2.transform(_dummies['终端品牌类型'].astype(str))\n",
    "\n",
    "def invert_type(data):\n",
    "    data[[i for i in data.columns if i in float_feature]] = data[[i for i in data.columns if i in float_feature]].astype(np.float64)\n",
    "    data[[i for i in data.columns if i in class_feature]] = data[[i for i in data.columns if i in class_feature]].astype(np.int64)\n",
    "\n",
    "def create_feature(data):\n",
    "    data['出现问题地点数'] = get_count(data, [i for i in data.columns if i in place_])\n",
    "    data['出现问题数'] = get_count(data, [i for i in data.columns if i in question_])\n",
    "\n",
    "def replace_all(data):\n",
    "    bad_data = data[data['其他，请注明'] == 1]\n",
    "    data_new = replace_place(data, bad_data, '用户描述')\n",
    "    _dummies = dummies_process(data_new)\n",
    "    bad_data = _dummies[_dummies['其他，请注明.1'] == 1]\n",
    "    _dummies = replace_question(_dummies, bad_data)\n",
    "    _dummies = dummies_process(_dummies, '用户描述.1', '其他，请注明.1', 'one_hot_test.csv')\n",
    "    return _dummies\n",
    "\n",
    "def pipeline(data: pd.DataFrame):\n",
    "    data[sound_dummies] = data[sound_dummies].fillna(-1).applymap(encoder)\n",
    "    drop_treat(data)\n",
    "    _dummies = replace_all(data)\n",
    "    _dummies = sample_clean(_dummies)\n",
    "    data_clean(_dummies)\n",
    "    transform(_dummies)\n",
    "    star_map(_dummies)\n",
    "    invert_type(_dummies)\n",
    "    create_feature(_dummies)\n",
    "    return _dummies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test = pipeline(test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test['是否投诉'] = test['是否投诉'].apply(lambda x: max(0, x))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "result = best_model.predict(test[train.columns])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "to_csv = read_excel(file_name='/result.xlsx')\n",
    "to_csv = pd.DataFrame(result, index=to_csv.index, columns=to_csv.columns)\n",
    "to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "to_csv.to_excel(RESULT_PATH + '/BMCB2202989 结果文档.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "matrix = pd.DataFrame(matrix, index=[i for i in range(1, 11)], columns=[i for i in range(1, 11)])\n",
    "sns.heatmap(StandardScaler().fit_transform(matrix))\n",
    "plt.xlim((1, 10))\n",
    "plt.ylim((1, 10))\n",
    "create_figure('result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_importance_ = pd.Series(rf.feature_importances_, index=train.columns)\n",
    "_importance_.sort_values(inplace=True, ascending=False)\n",
    "plt.figure(figsize=(20, 9))\n",
    "plt.bar(_importance_.index[:10], _importance_.values[:10])\n",
    "create_figure('importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_importance_.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "save_excel(dummies_n, file_name='clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from shap import TreeExplainer\n",
    "\n",
    "explainer = TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(train)\n",
    "shap_values2 = explainer(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
